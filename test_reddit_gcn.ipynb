{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4106225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral import datasets\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from spektral.layers import GCNConv, GlobalSumPool\n",
    "from spektral.data import Loader\n",
    "from spektral.transforms import GCNFilter\n",
    "from spektral.models.gcn import GCN\n",
    "from spektral.data.loaders import SingleLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c63f0",
   "metadata": {},
   "source": [
    "The Reddit dataset consists of a graph made of Reddit posts in the month of September, 2014. The label for each node is the community that a post belongs to. The graph is built by sampling 50 large communities and two nodes are connected if the same user commented on both. Node features are obtained by concatenating the average GloVe CommonCrawl vectors of the title and comments, the post's score and the number of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ddbd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading reddit dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1.22G/1.22G [01:50<00:00, 18.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1.22G/1.22G [02:01<00:00, 10.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "data = datasets.graphsage.Reddit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed24a0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reddit(n_graphs=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4891544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=232965, n_node_features=602, n_edge_features=None, n_labels=41)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reddit posts in the month of September, 2014\n",
    "reddit_graph = data[0]\n",
    "reddit_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51e51a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232965, 232965)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjacency matrix (two nodes are connected if the same user commented on both)\n",
    "adj_matrix = reddit_graph.a\n",
    "adj_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2db844f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x232965 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 367 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e757655c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232965, 602)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Node features (Node features are obtained by concatenating the average GloVe CommonCrawl vectors of the title and comments, \n",
    "#                the post's score and the number of comments)\n",
    "node_features = reddit_graph.x\n",
    "node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68b8f67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge features \n",
    "edge_features = reddit_graph.e\n",
    "type(edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "643339bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232965, 41)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels (The label for each node is the community that a post belongs to)\n",
    "targets = reddit_graph.y\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dffe697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform adj matrix for GCNConv\n",
    "data.apply(GCNFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "add4f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(n_labels=data.n_labels, n_input_channels=data.n_node_features)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss=CategoricalCrossentropy(reduction=\"sum\"),\n",
    "    weighted_metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43007465",
   "metadata": {},
   "source": [
    "However, here's where graphs get in our way. Unlike regular data, like images or sequences, graphs cannot be stretched, cut, or reshaped so that we can fit them into tensors of pre-defined shapes. If a graph has 10 nodes and another one has 4, we have to keep them that way.\n",
    "\n",
    "This means that iterating over a dataset in mini-batches is not trivial and we cannot simply use the model.fit() method of Keras as-is.\n",
    "\n",
    "We have to use a data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7790e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = SingleLoader(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9fc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 12:01:56.816952: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-08 12:01:56.820571: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2294685000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 110s 11s/step - loss: 920705.8750 - acc: 0.0770\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 109s 11s/step - loss: 831748.3750 - acc: 0.1029\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 108s 11s/step - loss: 812050.3750 - acc: 0.1204\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 100s 10s/step - loss: 805333.8750 - acc: 0.1203\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 100s 10s/step - loss: 803408.2500 - acc: 0.1206\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 100s 10s/step - loss: 802295.3750 - acc: 0.1208\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 100s 10s/step - loss: 801943.1250 - acc: 0.1208\n",
      "Epoch 8/10\n",
      " 4/10 [===========>..................] - ETA: 1:00 - loss: 801763.6250 - acc: 0.1209"
     ]
    }
   ],
   "source": [
    "model.fit(loader.load(), steps_per_epoch=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17b0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spektral",
   "language": "python",
   "name": "spektral"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
